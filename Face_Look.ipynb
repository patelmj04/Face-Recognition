{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tkinter import *\n",
    "from tkinter import messagebox\n",
    "from PIL import Image, ImageTk\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# facerecog.py\n",
    "import cv2\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox, simpledialog\n",
    "from PIL import Image, ImageTk\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "class FaceRecogApp:\n",
    "    def __init__(self, window):\n",
    "        self.window = window\n",
    "        self.window.title(\"FaceRecog - DNN Face Recognition\")\n",
    "        self.window.geometry(\"800x600\")\n",
    "\n",
    "        # Load DNN face detector\n",
    "        self.net = cv2.dnn.readNetFromCaffe(\n",
    "            \"deploy.prototxt\",\n",
    "            \"res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "        )\n",
    "        \n",
    "        # Initialize LBPH recognizer\n",
    "        self.recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "        self.face_running = False\n",
    "        self.training_data_dir = \"training_data\"\n",
    "        \n",
    "        # Load existing model if available\n",
    "        self.labels = {}\n",
    "        self.current_id = 0\n",
    "        if os.path.exists(\"trained_model.yml\") and os.path.exists(\"labels.pickle\"):\n",
    "            self.recognizer.read(\"trained_model.yml\")\n",
    "            with open(\"labels.pickle\", 'rb') as f:\n",
    "                self.labels = pickle.load(f)\n",
    "            self.current_id = max(self.labels.values(), default=-1) + 1\n",
    "        \n",
    "        # Initialize video capture\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        \n",
    "        # UI Elements\n",
    "        self.video_label = tk.Label(window)\n",
    "        self.video_label.pack(pady=10)\n",
    "        \n",
    "        btn_frame = tk.Frame(window)\n",
    "        btn_frame.pack(pady=10)\n",
    "        \n",
    "        tk.Button(btn_frame, text=\"Start Camera\", \n",
    "                 command=self.start_camera).pack(side=tk.LEFT, padx=5)\n",
    "        tk.Button(btn_frame, text=\"Stop Camera\", \n",
    "                 command=self.stop_camera).pack(side=tk.LEFT, padx=5)\n",
    "        tk.Button(btn_frame, text=\"Add New Face\", \n",
    "                 command=self.add_new_face).pack(side=tk.LEFT, padx=5)\n",
    "        tk.Button(btn_frame, text=\"Train Model\", \n",
    "                 command=self.train_model).pack(side=tk.LEFT, padx=5)\n",
    "        tk.Button(btn_frame, text=\"Quit\", \n",
    "                 command=self.quit_app).pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        if not os.path.exists(self.training_data_dir):\n",
    "            os.makedirs(self.training_data_dir)\n",
    "        \n",
    "        self.update_frame()\n",
    "\n",
    "    def update_frame(self):\n",
    "        ret, frame = self.cap.read()\n",
    "        if ret and self.face_running:\n",
    "            (h, w) = frame.shape[:2]\n",
    "            blob = cv2.dnn.blobFromImage(\n",
    "                cv2.resize(frame, (300, 300)), \n",
    "                1.0, \n",
    "                (300, 300), \n",
    "                (104.0, 177.0, 123.0)\n",
    "            )\n",
    "            \n",
    "            self.net.setInput(blob)\n",
    "            detections = self.net.forward()\n",
    "            \n",
    "            for i in range(detections.shape[2]):\n",
    "                confidence = detections[0, 0, i, 2]\n",
    "                if confidence > 0.5:\n",
    "                    box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                    (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "                    \n",
    "                    startX, startY = max(0, startX), max(0, startY)\n",
    "                    endX, endY = min(w-1, endX), min(h-1, endY)\n",
    "                    \n",
    "                    # Recognition\n",
    "                    face = frame[startY:endY, startX:endX]\n",
    "                    gray_face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "                    try:\n",
    "                        id_, conf = self.recognizer.predict(gray_face)\n",
    "                        label = [name for name, idx in self.labels.items() if idx == id_][0]\n",
    "                        text = f\"{label} ({conf:.2f})\" if conf < 100 else \"Unknown\"\n",
    "                    except:\n",
    "                        text = \"Unknown\"\n",
    "                    \n",
    "                    cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, text, (startX, startY-10),\n",
    "                              cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "            \n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            img = Image.fromarray(frame_rgb)\n",
    "            imgtk = ImageTk.PhotoImage(image=img)\n",
    "            self.video_label.imgtk = imgtk\n",
    "            self.video_label.configure(image=imgtk)\n",
    "        \n",
    "        self.window.after(10, self.update_frame)\n",
    "\n",
    "    def start_camera(self):\n",
    "        self.face_running = True\n",
    "        messagebox.showinfo(\"Info\", \"Camera started with DNN detection\")\n",
    "\n",
    "    def stop_camera(self):\n",
    "        self.face_running = False\n",
    "        messagebox.showinfo(\"Info\", \"Camera stopped\")\n",
    "\n",
    "    def add_new_face(self):\n",
    "        name = simpledialog.askstring(\"Input\", \"Enter person's name:\")\n",
    "        if not name:\n",
    "            return\n",
    "        \n",
    "        person_dir = os.path.join(self.training_data_dir, name)\n",
    "        if not os.path.exists(person_dir):\n",
    "            os.makedirs(person_dir)\n",
    "        \n",
    "        count = 0\n",
    "        messagebox.showinfo(\"Info\", \"Look at the camera. Capturing 30 samples...\")\n",
    "        \n",
    "        while count < 30:\n",
    "            ret, frame = self.cap.read()\n",
    "            if ret:\n",
    "                blob = cv2.dnn.blobFromImage(\n",
    "                    cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0)\n",
    "                )\n",
    "                self.net.setInput(blob)\n",
    "                detections = self.net.forward()\n",
    "                \n",
    "                if detections.shape[2] > 0:\n",
    "                    i = np.argmax(detections[0, 0, :, 2])\n",
    "                    confidence = detections[0, 0, i, 2]\n",
    "                    if confidence > 0.5:\n",
    "                        (h, w) = frame.shape[:2]\n",
    "                        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                        (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "                        \n",
    "                        startX, startY = max(0, startX), max(0, startY)\n",
    "                        endX, endY = min(w-1, endX), min(h-1, endY)\n",
    "                        \n",
    "                        face = frame[startY:endY, startX:endX]\n",
    "                        gray_face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "                        filename = f\"{person_dir}/sample_{count}.jpg\"\n",
    "                        cv2.imwrite(filename, gray_face)\n",
    "                        count += 1\n",
    "                        \n",
    "                        cv2.imshow(\"Capturing\", face)\n",
    "                        cv2.waitKey(100)\n",
    "        \n",
    "        cv2.destroyAllWindows()\n",
    "        if name not in self.labels:\n",
    "            self.labels[name] = self.current_id\n",
    "            self.current_id += 1\n",
    "        messagebox.showinfo(\"Success\", f\"Collected 30 samples for {name}\")\n",
    "\n",
    "    def train_model(self):\n",
    "        faces = []\n",
    "        ids = []\n",
    "        \n",
    "        for person_name, person_id in self.labels.items():\n",
    "            person_dir = os.path.join(self.training_data_dir, person_name)\n",
    "            for image_name in os.listdir(person_dir):\n",
    "                img_path = os.path.join(person_dir, image_name)\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                faces.append(img)\n",
    "                ids.append(person_id)\n",
    "        \n",
    "        if faces:\n",
    "            self.recognizer.train(faces, np.array(ids))\n",
    "            self.recognizer.save(\"trained_model.yml\")\n",
    "            with open(\"labels.pickle\", 'wb') as f:\n",
    "                pickle.dump(self.labels, f)\n",
    "            messagebox.showinfo(\"Success\", \"Model trained successfully\")\n",
    "        else:\n",
    "            messagebox.showwarning(\"Warning\", \"No training data found\")\n",
    "\n",
    "    def quit_app(self):\n",
    "        if messagebox.askokcancel(\"Quit\", \"Do you want to quit?\"):\n",
    "            self.cap.release()\n",
    "            self.window.destroy()\n",
    "\n",
    "def main():\n",
    "    if not (os.path.exists(\"deploy.prototxt\") and os.path.exists(\"res10_300x300_ssd_iter_140000.caffemodel\")):\n",
    "        print(\"Error: DNN model files not found. Please download:\")\n",
    "        print(\"1. deploy.prototxt\")\n",
    "        print(\"2. res10_300x300_ssd_iter_140000.caffemodel\")\n",
    "        return\n",
    "    \n",
    "    root = tk.Tk()\n",
    "    app = FaceRecogApp(root)\n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
